{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99f6f93",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fae1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: VAR1\n",
      "Loaded: maps_key\n",
      "Loaded: atlas_key_name\n",
      "Loaded: atlas_key\n",
      "\n",
      "Successfully loaded 4 environment variables from master.env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "    # Dependencies:\n",
    "    # - python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load env vars\n",
    "    # Manual\n",
    "    # load_dotenv(\"../.env/master.env\")\n",
    "    # maps_key = os.getenv(\"maps_key\")\n",
    "\n",
    "# Load all variables from the .env file into a dictionary\n",
    "env_vars = dotenv_values(\"../.env/master.env\")\n",
    "\n",
    "# Set them as environment variables\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "    print(f\"Loaded: {key}\")\n",
    "\n",
    "# Print\n",
    "print(f\"\\nSuccessfully loaded {len(env_vars)} environment variables from master.env\")\n",
    "\n",
    "# print(env_vars.get(\"VAR1\")) # call variable\n",
    "# VAR1 = env_vars.get(\"VAR1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf02a2",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cf4b1",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b79be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Municipalities data loaded successfully with correct data types.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                  int64\n",
       "mun_key               str\n",
       "mun_name              str\n",
       "mun_name_short        str\n",
       "mun_zip               str\n",
       "mun_pop_cen22       int64\n",
       "mun_pop_cen22m      int64\n",
       "mun_pop_cen22f      int64\n",
       "mun_dens_cen22      int64\n",
       "mun_sizekm2       float64\n",
       "state                 str\n",
       "lat               float64\n",
       "lon               float64\n",
       "geo                   str\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Municipalities\n",
    "    # Statistisches Bundesamt (2025)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_mun = pd.read_csv(\n",
    "    '../data/processed/municipalities.csv',\n",
    "    # Set data types\n",
    "    dtype={\n",
    "        'id': 'int64',\n",
    "        'mun_key': str,\n",
    "        'mun_name': str,\n",
    "        'mun_name_short': str,\n",
    "        'mun_zip': str,\n",
    "        'mun_pop_cen22': 'int64',\n",
    "        'mun_pop_cen22m': 'int64',\n",
    "        'mun_pop_cen22f': 'int64',\n",
    "        'mun_dens_cen22': 'int64',\n",
    "        'mun_sizekm2': 'float64',\n",
    "        'state': str,\n",
    "        'lat': 'float64',\n",
    "        'lon': 'float64',\n",
    "        'geo': str\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Shorten municipality name\n",
    "df_mun['mun_name_short'] = df_mun['mun_name'].str.split(',').str[0]\n",
    "df_mun['mun_name_short'] = df_mun['mun_name_short'].astype(str)  # correct data type\n",
    "\n",
    "# Print\n",
    "print(\"\\nMunicipalities data loaded successfully with correct data types.\\n\")\n",
    "df_mun\n",
    "df_mun.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2255e",
   "metadata": {},
   "source": [
    "### Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Geocoding completed. Updated municipalities data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mun_key</th>\n",
       "      <th>mun_name</th>\n",
       "      <th>mun_name_short</th>\n",
       "      <th>mun_zip</th>\n",
       "      <th>mun_pop_cen22</th>\n",
       "      <th>mun_pop_cen22m</th>\n",
       "      <th>mun_pop_cen22f</th>\n",
       "      <th>mun_dens_cen22</th>\n",
       "      <th>mun_sizekm2</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110000000000</td>\n",
       "      <td>Berlin, Stadt</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>10178</td>\n",
       "      <td>3685265</td>\n",
       "      <td>1810259</td>\n",
       "      <td>1875006</td>\n",
       "      <td>4136</td>\n",
       "      <td>891.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.522188</td>\n",
       "      <td>13.409331</td>\n",
       "      <td>52.5221879,13.4093313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>020000000000</td>\n",
       "      <td>Hamburg, Freie und Hansestadt</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>20038</td>\n",
       "      <td>1862565</td>\n",
       "      <td>911888</td>\n",
       "      <td>950677</td>\n",
       "      <td>2467</td>\n",
       "      <td>755.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.548828</td>\n",
       "      <td>9.987170</td>\n",
       "      <td>53.5488282,9.987170299999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>091620000000</td>\n",
       "      <td>München, Landeshauptstadt</td>\n",
       "      <td>München</td>\n",
       "      <td>80313</td>\n",
       "      <td>1505005</td>\n",
       "      <td>737442</td>\n",
       "      <td>767563</td>\n",
       "      <td>4844</td>\n",
       "      <td>310.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.135125</td>\n",
       "      <td>11.581981</td>\n",
       "      <td>48.1351253,11.5819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>053150000000</td>\n",
       "      <td>Köln, Stadt</td>\n",
       "      <td>Köln</td>\n",
       "      <td>50667</td>\n",
       "      <td>1024621</td>\n",
       "      <td>498050</td>\n",
       "      <td>526571</td>\n",
       "      <td>2530</td>\n",
       "      <td>405.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.938644</td>\n",
       "      <td>6.953885</td>\n",
       "      <td>50.9386437,6.9538847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>064120000000</td>\n",
       "      <td>Frankfurt am Main, Stadt</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>60311</td>\n",
       "      <td>756021</td>\n",
       "      <td>371235</td>\n",
       "      <td>384786</td>\n",
       "      <td>3045</td>\n",
       "      <td>248.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.110090</td>\n",
       "      <td>8.682249</td>\n",
       "      <td>50.1100897,8.6822492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       mun_key                       mun_name     mun_name_short mun_zip  mun_pop_cen22  mun_pop_cen22m  mun_pop_cen22f  mun_dens_cen22  mun_sizekm2 state        lat        lon  \\\n",
       "0   1  110000000000                  Berlin, Stadt             Berlin   10178        3685265         1810259         1875006            4136       891.12   NaN  52.522188  13.409331   \n",
       "1   2  020000000000  Hamburg, Freie und Hansestadt            Hamburg   20038        1862565          911888          950677            2467       755.09   NaN  53.548828   9.987170   \n",
       "2   3  091620000000      München, Landeshauptstadt            München   80313        1505005          737442          767563            4844       310.70   NaN  48.135125  11.581981   \n",
       "3   4  053150000000                    Köln, Stadt               Köln   50667        1024621          498050          526571            2530       405.02   NaN  50.938644   6.953885   \n",
       "4   5  064120000000       Frankfurt am Main, Stadt  Frankfurt am Main   60311         756021          371235          384786            3045       248.31   NaN  50.110090   8.682249   \n",
       "\n",
       "                            geo  \n",
       "0         52.5221879,13.4093313  \n",
       "1  53.5488282,9.987170299999999  \n",
       "2         48.1351253,11.5819806  \n",
       "3          50.9386437,6.9538847  \n",
       "4          50.1100897,8.6822492  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add coordinates\n",
    "    # Dependencies:\n",
    "    # - geopy\n",
    "    # - Google Maps Geocoding API\n",
    "    # Note: ZIP codes *alone* do not always resolve to postal codes or locations during geocoding, hence, mun_name\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from geopy.geocoders import GoogleV3\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Initialize geocoder\n",
    "geolocator = GoogleV3(api_key=env_vars.get(\"maps_key\"))\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.05) # 50 request/sec allowed\n",
    "\n",
    "# Function to geocode each row\n",
    "def get_coordinates(row):\n",
    "    try:\n",
    "        query = f\"{row['mun_name_short']}, {row['mun_zip']}, Germany\"\n",
    "        location = geocode(query)\n",
    "        if location:\n",
    "            return pd.Series({'lat': location.latitude, 'lon': location.longitude})\n",
    "        else:\n",
    "            return pd.Series({'lat': None, 'lon': None})\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {row['mun_name_short']}: {e}\")\n",
    "        return pd.Series({'lat': None, 'lon': None})\n",
    "\n",
    "# Apply geocoding to each row\n",
    "df_mun[['lat', 'lon']] = df_mun.apply(get_coordinates, axis=1)\n",
    "\n",
    "# Combine into geo col (string: \"lat,lon\")\n",
    "df_mun['geo'] = df_mun['lat'].astype(str) + ',' + df_mun['lon'].astype(str)\n",
    "\n",
    "# Print\n",
    "print(\"\\nGeocoding completed. Updated municipalities data:\\n\")\n",
    "df_mun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc138b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Municipalities data (geocoded) saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "df_mun.to_csv('../data/processed/municipalities_geocoded.csv', index=False, encoding='utf-8')  # UTF-8 encoding\n",
    "\n",
    "# Print\n",
    "print(\"\\nMunicipalities data (geocoded) saved successfully.\")\n",
    "print(\"\\nRows:\")\n",
    "df_mun.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f7187",
   "metadata": {},
   "source": [
    "### Adding federal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29646d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add federal states\n",
    "    # Dependencies:\n",
    "    # - OpenPLZ API\n",
    "    # Example: curl -X GET 'https://openplzapi.org/de/Localities?postalCode=13156' -H 'accept: text/json' | ConvertFrom-Json | ConvertTo-Json\n",
    "\n",
    "# Potential corrections:\n",
    "# - retries when timeout\n",
    "# - exponential backoff for rate limiting (error status 429)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Initialize/clear list for state names\n",
    "states = []\n",
    "\n",
    "# Rate limiting\n",
    "REQUEST_DELAY = 0.5  # max 2 requests/sec\n",
    "\n",
    "# Iterate over each postal code (zip) in df_mun\n",
    "for i, postal_code in enumerate(df_mun['mun_zip']):\n",
    "    try:\n",
    "        # Build API URL with zip\n",
    "        url = f'https://openplzapi.org/de/Localities?postalCode={postal_code}'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'  # Force UTF-8 encoding\n",
    "        \n",
    "        # Extract state name from first result\n",
    "        data = response.json()\n",
    "        if data and len(data) > 0:\n",
    "            state_name = data[0]['federalState']['name']\n",
    "            states.append(state_name)\n",
    "        else:\n",
    "            states.append(None)  # No data found for this postal code\n",
    "        \n",
    "        # Wait before next request\n",
    "        if i < len(df_mun) - 1:  # No wait after the very last request\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    except Exception as e:\n",
    "        states.append(None)  # Handle errors gracefully\n",
    "\n",
    "# Add state column to df_mun\n",
    "df_mun['state'] = states\n",
    "\n",
    "print(\"\\nAdding federal states: 1st run completed. Updated municipalities data:\\n\")\n",
    "print(f\"\\nRows: {df_mun.shape[0]}\\n\")\n",
    "df_mun.head()\n",
    "\n",
    "# Unique values\n",
    "state_counts = df_mun['state'].value_counts(dropna=False).reset_index()\n",
    "state_counts.columns = ['State', 'Count']\n",
    "state_counts = state_counts.sort_values('State')\n",
    "state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32892b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data\n",
    "df_mun.to_csv('../data/processed/municipalities_geocoded_state1.csv', index=False, encoding='utf-8')  # UTF-8 encoding\n",
    "\n",
    "# Print\n",
    "print(\"\\nMunicipalities data (geocoded + states [1st run] ) saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear list \"states\"\n",
    "states = []\n",
    "\n",
    "# Catch & re-run empty responses\n",
    "    # Iterate over each NaN (state) in df_mun\n",
    "\n",
    "for i, row in df_mun[df_mun['state'].isna()].iterrows():\n",
    "    try:\n",
    "        # Build API URL with mun_name_short\n",
    "        url = f'https://openplzapi.org/de/FullTextSearch?searchTerm={row[\"mun_name_short\"]}'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'  # Force UTF-8 encoding\n",
    "        \n",
    "        # Extract state name from first result\n",
    "        data = response.json()\n",
    "        if data and len(data) > 0:\n",
    "            state_name = data[0]['federalState']['name']\n",
    "            df_mun.at[i, 'state'] = state_name\n",
    "        \n",
    "        # Wait before next request\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass  # Handle errors gracefully\n",
    "\n",
    "# Print\n",
    "print(\"\\nAdding federal states: 2st (final) run completed. Updated municipalities data:\\n\")\n",
    "print(f\"\\nRows: {df_mun.shape[0]}\\n\")\n",
    "\n",
    "df_mun.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18b7a0",
   "metadata": {},
   "source": [
    "### Adding federal states (backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d3b0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add federal states\n",
    "    # Dependencies: -\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data: Municipalities (geocoded)\n",
    "\n",
    "df_mun = pd.read_csv(\n",
    "    '../data/processed/municipalities_geocoded.csv',\n",
    "    # Set data types\n",
    "    dtype={\n",
    "        'id': 'int64',\n",
    "        'mun_key': str,\n",
    "        'mun_name': str,\n",
    "        'mun_name_short': str,\n",
    "        'mun_zip': str,\n",
    "        'mun_pop_cen22': 'int64',\n",
    "        'mun_pop_cen22m': 'int64',\n",
    "        'mun_pop_cen22f': 'int64',\n",
    "        'mun_dens_cen22': 'int64',\n",
    "        'mun_sizekm2': 'float64',\n",
    "        'state': str,\n",
    "        'lat': 'float64',\n",
    "        'lon': 'float64',\n",
    "        'geo': str\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Load data: ZIP codes & Federal states\n",
    "\n",
    "df_zip = pd.read_csv(\n",
    "    '../data/processed/plz23.csv', \n",
    "    delimiter=';', \n",
    "    encoding='utf-8',\n",
    "    dtype={\n",
    "        'PLZ': 'str',\n",
    "        'ORT': str,\n",
    "        'ZUSATZ': 'str',\n",
    "        'BUNDESLAND': str\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d1c5a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique states in the dataset:\n",
      "\n",
      "                     state  count\n",
      "1        Baden-Württemberg   1189\n",
      "0                   Bayern   2073\n",
      "11                  Berlin    191\n",
      "9              Brandenburg    211\n",
      "15                  Bremen     33\n",
      "13                 Hamburg    100\n",
      "5                   Hessen    551\n",
      "12  Mecklenburg-Vorpommern    191\n",
      "3            Niedersachsen    809\n",
      "2      Nordrhein-Westfalen    876\n",
      "4          Rheinland-Pfalz    643\n",
      "14                Saarland     69\n",
      "7                  Sachsen    378\n",
      "10          Sachsen-Anhalt    205\n",
      "6       Schleswig-Holstein    441\n",
      "8                Thüringen    213\n",
      "\n",
      "Header:\n",
      "\n",
      "     zip municipality    state\n",
      "0  01067      Dresden  Sachsen\n",
      "1  01069      Dresden  Sachsen\n",
      "2  01097      Dresden  Sachsen\n",
      "3  01099      Dresden  Sachsen\n",
      "4  01108      Dresden  Sachsen\n"
     ]
    }
   ],
   "source": [
    "# Clean ZIP data\n",
    "\n",
    "# Rename\n",
    "df_zip = df_zip[['PLZ', 'ORT', 'BUNDESLAND']]\n",
    "df_zip = df_zip.rename(columns={'PLZ': 'zip', 'ORT': 'municipality', 'BUNDESLAND': 'state'})\n",
    "\n",
    "# Correct values for \"Berlin\"\n",
    "df_zip.loc[df_zip['municipality'] == 'Berlin', 'state'] = 'Berlin'\n",
    "\n",
    "# Drop NA\n",
    "df_zip = df_zip.dropna(subset=['state'])\n",
    "\n",
    "# Drop duplicates (for later matching)\n",
    "df_zip = df_zip.drop_duplicates(subset=['zip'])\n",
    "\n",
    "# Examine unique values\n",
    "state_counts_zip = df_zip['state'].value_counts(dropna=False).reset_index()\n",
    "state_counts_zip.columns = ['state', 'count']\n",
    "state_counts_zip = state_counts_zip.sort_values('state')\n",
    "\n",
    "# Print\n",
    "print(\"\\nUnique states in the dataset:\\n\")\n",
    "print(state_counts_zip)\n",
    "print(\"\\nHeader:\\n\")\n",
    "print(df_zip.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows still unmatched: 3 out of 2059\n",
      "\n",
      "----\n",
      "Matching complete.\n",
      "\n",
      "Unique states in the dataset:\n",
      "\n",
      "                     state  count\n",
      "1        Baden-Württemberg    313\n",
      "0                   Bayern    319\n",
      "14                  Berlin      1\n",
      "8              Brandenburg    112\n",
      "16                  Bremen      1\n",
      "15                 Hamburg      1\n",
      "3                   Hessen    190\n",
      "10  Mecklenburg-Vorpommern     85\n",
      "5            Niedersachsen    160\n",
      "2      Nordrhein-Westfalen    273\n",
      "6          Rheinland-Pfalz    129\n",
      "12                Saarland     17\n",
      "4                  Sachsen    164\n",
      "9           Sachsen-Anhalt    108\n",
      "11      Schleswig-Holstein     63\n",
      "7                Thüringen    120\n",
      "13                     NaN      3\n",
      "\n",
      "Header:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mun_key</th>\n",
       "      <th>mun_name</th>\n",
       "      <th>mun_name_short</th>\n",
       "      <th>mun_zip</th>\n",
       "      <th>mun_pop_cen22</th>\n",
       "      <th>mun_pop_cen22m</th>\n",
       "      <th>mun_pop_cen22f</th>\n",
       "      <th>mun_dens_cen22</th>\n",
       "      <th>mun_sizekm2</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110000000000</td>\n",
       "      <td>Berlin, Stadt</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>10178</td>\n",
       "      <td>3685265</td>\n",
       "      <td>1810259</td>\n",
       "      <td>1875006</td>\n",
       "      <td>4136</td>\n",
       "      <td>891.12</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.522188</td>\n",
       "      <td>13.409331</td>\n",
       "      <td>52.5221879,13.4093313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>020000000000</td>\n",
       "      <td>Hamburg, Freie und Hansestadt</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>20038</td>\n",
       "      <td>1862565</td>\n",
       "      <td>911888</td>\n",
       "      <td>950677</td>\n",
       "      <td>2467</td>\n",
       "      <td>755.09</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>53.548828</td>\n",
       "      <td>9.987170</td>\n",
       "      <td>53.5488282,9.987170299999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>091620000000</td>\n",
       "      <td>München, Landeshauptstadt</td>\n",
       "      <td>München</td>\n",
       "      <td>80313</td>\n",
       "      <td>1505005</td>\n",
       "      <td>737442</td>\n",
       "      <td>767563</td>\n",
       "      <td>4844</td>\n",
       "      <td>310.70</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>48.135125</td>\n",
       "      <td>11.581981</td>\n",
       "      <td>48.1351253,11.5819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>053150000000</td>\n",
       "      <td>Köln, Stadt</td>\n",
       "      <td>Köln</td>\n",
       "      <td>50667</td>\n",
       "      <td>1024621</td>\n",
       "      <td>498050</td>\n",
       "      <td>526571</td>\n",
       "      <td>2530</td>\n",
       "      <td>405.02</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>50.938644</td>\n",
       "      <td>6.953885</td>\n",
       "      <td>50.9386437,6.9538847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>064120000000</td>\n",
       "      <td>Frankfurt am Main, Stadt</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>60311</td>\n",
       "      <td>756021</td>\n",
       "      <td>371235</td>\n",
       "      <td>384786</td>\n",
       "      <td>3045</td>\n",
       "      <td>248.31</td>\n",
       "      <td>Hessen</td>\n",
       "      <td>50.110090</td>\n",
       "      <td>8.682249</td>\n",
       "      <td>50.1100897,8.6822492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       mun_key                       mun_name     mun_name_short mun_zip  mun_pop_cen22  mun_pop_cen22m  mun_pop_cen22f  mun_dens_cen22  mun_sizekm2                state        lat        lon  \\\n",
       "0   1  110000000000                  Berlin, Stadt             Berlin   10178        3685265         1810259         1875006            4136       891.12               Berlin  52.522188  13.409331   \n",
       "1   2  020000000000  Hamburg, Freie und Hansestadt            Hamburg   20038        1862565          911888          950677            2467       755.09              Hamburg  53.548828   9.987170   \n",
       "2   3  091620000000      München, Landeshauptstadt            München   80313        1505005          737442          767563            4844       310.70               Bayern  48.135125  11.581981   \n",
       "3   4  053150000000                    Köln, Stadt               Köln   50667        1024621          498050          526571            2530       405.02  Nordrhein-Westfalen  50.938644   6.953885   \n",
       "4   5  064120000000       Frankfurt am Main, Stadt  Frankfurt am Main   60311         756021          371235          384786            3045       248.31               Hessen  50.110090   8.682249   \n",
       "\n",
       "                            geo  \n",
       "0         52.5221879,13.4093313  \n",
       "1  53.5488282,9.987170299999999  \n",
       "2         48.1351253,11.5819806  \n",
       "3          50.9386437,6.9538847  \n",
       "4          50.1100897,8.6822492  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Match by zip code to fill state column\n",
    "df_mun['state'] = df_mun['mun_zip'].map(df_zip.set_index('zip')['state']).fillna(df_mun['state'])\n",
    "\n",
    "# Step 2: For unmatched rows, match by municipality name\n",
    "mun_to_state = df_zip.groupby('municipality')['state'].first()\n",
    "mask = df_mun['state'].isna()\n",
    "df_mun.loc[mask, 'state'] = df_mun.loc[mask, 'mun_name_short'].map(mun_to_state)\n",
    "\n",
    "# Check results\n",
    "unmatched = df_mun['state'].isna().sum()\n",
    "print(f\"Rows still unmatched: {unmatched} out of {len(df_mun)}\")\n",
    "\n",
    "# Drop remaining unmatched rows\n",
    "# -- not necessary --\n",
    "\n",
    "# Examine unique values\n",
    "state_counts = df_mun['state'].value_counts(dropna=False).reset_index()\n",
    "state_counts.columns = ['state', 'count']\n",
    "state_counts = state_counts.sort_values('state')\n",
    "state_counts\n",
    "\n",
    "# Print\n",
    "print(\"\\n----\\nMatching complete.\")\n",
    "print(\"\\nUnique states in the dataset:\\n\")  # city-states should be *unique* !\n",
    "print(state_counts)\n",
    "print(\"\\nHeader:\\n\")\n",
    "df_mun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d280626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Municipalities data (geocoded + states) saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "df_mun.to_csv('../data/processed/municipalities_full.csv', index=False, encoding='utf-8')  # UTF-8 encoding\n",
    "\n",
    "# Print\n",
    "print(\"\\nMunicipalities data (geocoded + states) saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2793e",
   "metadata": {},
   "source": [
    "# Sampling Origins: Municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9885b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Municipalities data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Sample Origin locations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_mun = pd.read_csv(\n",
    "    '../data/processed/municipalities_full.csv',\n",
    "    # Set data types\n",
    "    dtype={\n",
    "        'id': 'int64',\n",
    "        'mun_key': str,\n",
    "        'mun_name': str,\n",
    "        'mun_name_short': str,\n",
    "        'mun_zip': str,\n",
    "        'mun_pop_cen22': 'int64',\n",
    "        'mun_pop_cen22m': 'int64',\n",
    "        'mun_pop_cen22f': 'int64',\n",
    "        'mun_dens_cen22': 'int64',\n",
    "        'mun_sizekm2': 'float64',\n",
    "        'state': str,\n",
    "        'lat': 'float64',\n",
    "        'lon': 'float64',\n",
    "        'geo': str\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\nMunicipalities data loaded successfully.\")\n",
    "#df_mun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample municipalities selected successfully. Sample data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mun_key</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>mun_name_short</th>\n",
       "      <th>mun_pop_cen22</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>081110000000</td>\n",
       "      <td>top</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>612663</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>48.782703</td>\n",
       "      <td>9.182863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>082120000000</td>\n",
       "      <td>top</td>\n",
       "      <td>Karlsruhe</td>\n",
       "      <td>309050</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>49.006750</td>\n",
       "      <td>8.393843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>083110000000</td>\n",
       "      <td>top</td>\n",
       "      <td>Freiburg im Breisgau</td>\n",
       "      <td>237460</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>47.993854</td>\n",
       "      <td>7.846758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>084375001047</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Hettingen</td>\n",
       "      <td>1861</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>48.218306</td>\n",
       "      <td>9.233478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>081255007103</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Widdern</td>\n",
       "      <td>1782</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>49.316383</td>\n",
       "      <td>9.415555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>160715053061</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Neumark</td>\n",
       "      <td>462</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>51.079752</td>\n",
       "      <td>11.247166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>160695004052</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Ummerstadt</td>\n",
       "      <td>455</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>50.260149</td>\n",
       "      <td>10.812872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>160690062062</td>\n",
       "      <td>median</td>\n",
       "      <td>Römhild</td>\n",
       "      <td>6383</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>50.385059</td>\n",
       "      <td>10.575825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>160630103103</td>\n",
       "      <td>median</td>\n",
       "      <td>Werra-Suhl-Tal</td>\n",
       "      <td>6028</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>50.929777</td>\n",
       "      <td>10.112156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>160700058058</td>\n",
       "      <td>median</td>\n",
       "      <td>Großbreitenbach</td>\n",
       "      <td>5884</td>\n",
       "      <td>Thüringen</td>\n",
       "      <td>50.592129</td>\n",
       "      <td>11.046411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mun_key sample_type        mun_name_short  mun_pop_cen22              state        lat        lon\n",
       "0    081110000000         top             Stuttgart         612663  Baden-Württemberg  48.782703   9.182863\n",
       "1    082120000000         top             Karlsruhe         309050  Baden-Württemberg  49.006750   8.393843\n",
       "2    083110000000         top  Freiburg im Breisgau         237460  Baden-Württemberg  47.993854   7.846758\n",
       "3    084375001047      bottom             Hettingen           1861  Baden-Württemberg  48.218306   9.233478\n",
       "4    081255007103      bottom               Widdern           1782  Baden-Württemberg  49.316383   9.415555\n",
       "..            ...         ...                   ...            ...                ...        ...        ...\n",
       "115  160715053061      bottom               Neumark            462          Thüringen  51.079752  11.247166\n",
       "116  160695004052      bottom            Ummerstadt            455          Thüringen  50.260149  10.812872\n",
       "117  160690062062      median               Römhild           6383          Thüringen  50.385059  10.575825\n",
       "118  160630103103      median        Werra-Suhl-Tal           6028          Thüringen  50.929777  10.112156\n",
       "119  160700058058      median       Großbreitenbach           5884          Thüringen  50.592129  11.046411\n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get top, bottom, median municipalities for each state\n",
    "\n",
    "def get_sample_municipalities(group):\n",
    "    sorted_group = group.sort_values('mun_pop_cen22', ascending=False)\n",
    "    \n",
    "    # Only process if group has enough municipalities\n",
    "    if len(sorted_group) < 9:\n",
    "        # For small groups, label \"all\"\n",
    "        result = sorted_group.copy()\n",
    "        result['sample_type'] = 'all'\n",
    "        return result\n",
    "    \n",
    "    # Get largest 3\n",
    "    top = sorted_group.head(3).copy()\n",
    "    top['sample_type'] = 'top'\n",
    "    \n",
    "    # Get smallest 3\n",
    "    bottom = sorted_group.tail(3).copy()\n",
    "    bottom['sample_type'] = 'bottom'\n",
    "    \n",
    "    # Get median 3\n",
    "    n = len(sorted_group)\n",
    "    mid_start = max(0, (n // 2) - 1)\n",
    "    mid_end = min(n, mid_start + 3)\n",
    "    median = sorted_group.iloc[mid_start:mid_end].copy()\n",
    "    median['sample_type'] = 'median'\n",
    "    \n",
    "    return pd.concat([top, bottom, median]).drop_duplicates(subset=['mun_key'])\n",
    "\n",
    "# Apply to each state and create new df\n",
    "df_mun_sample = df_mun.groupby('state').apply(get_sample_municipalities).reset_index(level=0).reset_index(drop=True)\n",
    "\n",
    "df_mun_sample = df_mun_sample[['mun_key', 'sample_type', 'mun_name_short', 'mun_pop_cen22', 'state', 'lat', 'lon']]\n",
    "\n",
    "# Small sample\n",
    "df_mun_sample_small = df_mun_sample[df_mun_sample['state'] == 'bayern']  # Selected Bayern (BY) for small sample (n=9)\n",
    "\n",
    "# Print\n",
    "print(\"\\nSample municipalities selected successfully. Sample data:\\n\")\n",
    "df_mun_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled municipalities data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "df_mun_sample.to_csv('../data/processed/municipalities_full_sample.csv', index=False, encoding='utf-8')  # UTF-8 encoding\n",
    "# df_mun_sample_small.to_csv('../data/processed/municipalities_full_sample_small.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Print\n",
    "print(\"\\nSampled municipalities data saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c57797",
   "metadata": {},
   "source": [
    "# Sampling Origins: Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling RIPE Atlas Probe locations\n",
    "    # Dependencies:\n",
    "    # - RIPE Atlas API (atlas_key_name, atlas_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf2906",
   "metadata": {},
   "source": [
    "### Collect probe identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece60e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 probes so far...\n",
      "Fetched 200 probes so far...\n",
      "Fetched 300 probes so far...\n",
      "Fetched 400 probes so far...\n",
      "Fetched 500 probes so far...\n",
      "Fetched 600 probes so far...\n",
      "Fetched 700 probes so far...\n",
      "Fetched 800 probes so far...\n",
      "Fetched 900 probes so far...\n",
      "Fetched 1000 probes so far...\n",
      "Fetched 1100 probes so far...\n",
      "Fetched 1200 probes so far...\n",
      "Fetched 1300 probes so far...\n",
      "Fetched 1400 probes so far...\n",
      "Fetched 1500 probes so far...\n",
      "Fetched 1600 probes so far...\n",
      "Fetched 1700 probes so far...\n",
      "Fetched 1761 probes so far...\n",
      "\n",
      "Total probes with coordinates: 1761\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probe_id</th>\n",
       "      <th>asn</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>3320</td>\n",
       "      <td>49.4905</td>\n",
       "      <td>10.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>3209</td>\n",
       "      <td>52.3905</td>\n",
       "      <td>9.8105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>50629</td>\n",
       "      <td>53.0875</td>\n",
       "      <td>8.8305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>3320</td>\n",
       "      <td>52.3875</td>\n",
       "      <td>9.8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>3209</td>\n",
       "      <td>49.1475</td>\n",
       "      <td>9.2915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probe_id    asn      lat      lon\n",
       "0        46   3320  49.4905  10.9495\n",
       "1        67   3209  52.3905   9.8105\n",
       "2        71  50629  53.0875   8.8305\n",
       "3        80   3320  52.3875   9.8115\n",
       "4        81   3209  49.1475   9.2915"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the population (all healthy probes with coordinates and ipv4 address in Germany)\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_all_probes(country_code=\"DE\"):\n",
    "    url = \"https://atlas.ripe.net/api/v2/probes/\"\n",
    "    params = {\n",
    "        \"country_code\": country_code,\n",
    "        \"fields\": \"id,asn_v4,geometry\",  # collect these fields\n",
    "        \"tags\": \"system-ipv4-works\",  # filter by system tag; system-ipv6-works, system-ipv4-stable-1d, system-ipv4-stable-30d, system-ipv4-stable-90d\n",
    "        \"status\": 1,  # only active probes\n",
    "        \"format\": \"json\",\n",
    "        \"page_size\": 100\n",
    "    }\n",
    "    \n",
    "    probes = []\n",
    "    \n",
    "    while url:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        for probe in data[\"results\"]:\n",
    "            coords = probe.get(\"geometry\") or {}\n",
    "            coordinates = coords.get(\"coordinates\", [None, None])\n",
    "            probes.append({\n",
    "                \"probe_id\": probe[\"id\"],\n",
    "                \"asn\": probe.get(\"asn_v4\"),\n",
    "                \"lon\": coordinates[0],  # GeoJSON is [lon, lat]\n",
    "                \"lat\": coordinates[1],\n",
    "            })\n",
    "        \n",
    "        print(f\"Fetched {len(probes)} probes so far...\")\n",
    "        url = data.get(\"next\")\n",
    "        params = {}\n",
    "    \n",
    "    df = pd.DataFrame(probes, columns=[\"probe_id\", \"asn\", \"lat\", \"lon\"])\n",
    "    df = df.dropna(subset=[\"lat\", \"lon\"])  # exclude probes without coordinates\n",
    "    df[\"asn\"] = df[\"asn\"].astype(\"Int64\")  # convert to integer type\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_probes_de = get_all_probes(\"DE\")\n",
    "\n",
    "# Print\n",
    "# expected: ~1759\n",
    "print(f\"\\nTotal probes with coordinates: {len(df_probes_de)}\\n\")\n",
    "# print(df.to_string(index=False))\n",
    "df_probes_de.dtypes\n",
    "df_probes_de.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probes data (id, asn, health, ipv4, coordinates) saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "# Write\n",
    "df_probes_de.to_csv(f'../data/processed/probes_de_{timestamp}.csv', index=False, encoding='utf-8')  # UTF-8 encoding\n",
    "\n",
    "# Print\n",
    "print(\"\\nProbes data (id, asn, health, ipv4, coordinates) saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e628ee",
   "metadata": {},
   "source": [
    "### Create distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed4c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix created: 1761 probes × 120 municipalities\n",
      "\n",
      "First few rows and columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mun_key</th>\n",
       "      <th>081110000000</th>\n",
       "      <th>082120000000</th>\n",
       "      <th>083110000000</th>\n",
       "      <th>084375001047</th>\n",
       "      <th>081255007103</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>151.040448</td>\n",
       "      <td>193.680033</td>\n",
       "      <td>282.409358</td>\n",
       "      <td>189.394100</td>\n",
       "      <td>113.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>403.781905</td>\n",
       "      <td>389.475251</td>\n",
       "      <td>508.706577</td>\n",
       "      <td>465.906034</td>\n",
       "      <td>343.108953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>479.533947</td>\n",
       "      <td>455.008818</td>\n",
       "      <td>570.873656</td>\n",
       "      <td>542.403095</td>\n",
       "      <td>421.528487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>403.458065</td>\n",
       "      <td>389.171635</td>\n",
       "      <td>508.406591</td>\n",
       "      <td>465.579911</td>\n",
       "      <td>342.782016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>41.341277</td>\n",
       "      <td>67.423397</td>\n",
       "      <td>166.802773</td>\n",
       "      <td>103.417930</td>\n",
       "      <td>20.842327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mun_key   081110000000  082120000000  083110000000  084375001047  081255007103\n",
       "probe_id                                                                      \n",
       "46          151.040448    193.680033    282.409358    189.394100    113.001679\n",
       "67          403.781905    389.475251    508.706577    465.906034    343.108953\n",
       "71          479.533947    455.008818    570.873656    542.403095    421.528487\n",
       "80          403.458065    389.171635    508.406591    465.579911    342.782016\n",
       "81           41.341277     67.423397    166.802773    103.417930     20.842327"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize distance matrix\n",
    "# Rows: probe_id, Columns: mun_key\n",
    "distance_data = {}\n",
    "\n",
    "# Calculate distance for each probe to each municipality\n",
    "for _, probe in df_probes_de.iterrows():\n",
    "    probe_coords = (probe['lat'], probe['lon'])\n",
    "    distances = []\n",
    "    \n",
    "    for _, mun in df_mun_sample.iterrows():\n",
    "        mun_coords = (mun['lat'], mun['lon'])\n",
    "        # Calculate geodesic distance in kilometers\n",
    "        dist_km = geodesic(probe_coords, mun_coords).kilometers\n",
    "        distances.append(dist_km)\n",
    "    \n",
    "    distance_data[probe['probe_id']] = distances\n",
    "\n",
    "# Create DataFrame with probe_ids as columns, mun_keys as index\n",
    "df_probes_distance = pd.DataFrame(\n",
    "    distance_data,\n",
    "    index=df_mun_sample['mun_key']\n",
    ").T\n",
    "\n",
    "# Set index name\n",
    "df_probes_distance.index.name = 'probe_id'\n",
    "\n",
    "print(f\"\\nDistance matrix created: {df_probes_distance.shape[0]} probes × {df_probes_distance.shape[1]} municipalities\")\n",
    "print(f\"\\nFirst 5 rows and columns:\")\n",
    "df_probes_distance.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa6584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full distance matrix saved to '../data/processed/probes_distance_matrix.csv'\n",
      "Shape: 1761 probes × 120 municipalities\n"
     ]
    }
   ],
   "source": [
    "# Write probe distance matrix to CSV\n",
    "df_probes_distance.to_csv('../data/processed/probes_distance_matrix.csv', encoding='utf-8')\n",
    "\n",
    "print(\"\\nFull distance matrix saved successfully.\")\n",
    "print(f\"Shape: {df_probes_distance.shape[0]} probes × {df_probes_distance.shape[1]} municipalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82ab8b",
   "metadata": {},
   "source": [
    "### Matching locations to closest probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5000988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probe-1</th>\n",
       "      <th>probe-2</th>\n",
       "      <th>probe-3</th>\n",
       "      <th>probe-4</th>\n",
       "      <th>probe-5</th>\n",
       "      <th>distance-1</th>\n",
       "      <th>distance-2</th>\n",
       "      <th>distance-3</th>\n",
       "      <th>distance-4</th>\n",
       "      <th>distance-5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mun_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>081110000000</th>\n",
       "      <td>19869</td>\n",
       "      <td>22109</td>\n",
       "      <td>21574</td>\n",
       "      <td>19836</td>\n",
       "      <td>19837</td>\n",
       "      <td>0.219192</td>\n",
       "      <td>0.366082</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.403501</td>\n",
       "      <td>0.403501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>082120000000</th>\n",
       "      <td>11194</td>\n",
       "      <td>52831</td>\n",
       "      <td>21421</td>\n",
       "      <td>21441</td>\n",
       "      <td>896</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>0.350778</td>\n",
       "      <td>0.399705</td>\n",
       "      <td>0.422199</td>\n",
       "      <td>0.450911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>083110000000</th>\n",
       "      <td>1013945</td>\n",
       "      <td>11729</td>\n",
       "      <td>1004771</td>\n",
       "      <td>1010559</td>\n",
       "      <td>29215</td>\n",
       "      <td>0.660241</td>\n",
       "      <td>1.966321</td>\n",
       "      <td>3.476046</td>\n",
       "      <td>4.190831</td>\n",
       "      <td>6.377792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>084375001047</th>\n",
       "      <td>52839</td>\n",
       "      <td>19884</td>\n",
       "      <td>51094</td>\n",
       "      <td>52995</td>\n",
       "      <td>11296</td>\n",
       "      <td>11.799138</td>\n",
       "      <td>15.042199</td>\n",
       "      <td>24.252101</td>\n",
       "      <td>24.252101</td>\n",
       "      <td>26.778651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>081255007103</th>\n",
       "      <td>29222</td>\n",
       "      <td>18811</td>\n",
       "      <td>25329</td>\n",
       "      <td>81</td>\n",
       "      <td>29951</td>\n",
       "      <td>16.592880</td>\n",
       "      <td>16.720524</td>\n",
       "      <td>20.260771</td>\n",
       "      <td>20.842327</td>\n",
       "      <td>21.648458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>081275004047</th>\n",
       "      <td>1010576</td>\n",
       "      <td>62217</td>\n",
       "      <td>20250</td>\n",
       "      <td>55713</td>\n",
       "      <td>18811</td>\n",
       "      <td>17.252451</td>\n",
       "      <td>21.091341</td>\n",
       "      <td>26.484352</td>\n",
       "      <td>30.365620</td>\n",
       "      <td>31.501102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>081350020020</th>\n",
       "      <td>1506</td>\n",
       "      <td>1006858</td>\n",
       "      <td>1011407</td>\n",
       "      <td>53353</td>\n",
       "      <td>24357</td>\n",
       "      <td>22.270402</td>\n",
       "      <td>24.359167</td>\n",
       "      <td>24.929800</td>\n",
       "      <td>25.714412</td>\n",
       "      <td>28.041415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>083260003003</th>\n",
       "      <td>51017</td>\n",
       "      <td>32134</td>\n",
       "      <td>1009411</td>\n",
       "      <td>33886</td>\n",
       "      <td>6761</td>\n",
       "      <td>13.553900</td>\n",
       "      <td>14.697697</td>\n",
       "      <td>18.883913</td>\n",
       "      <td>26.284859</td>\n",
       "      <td>30.270263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>083370116116</th>\n",
       "      <td>4332</td>\n",
       "      <td>1005212</td>\n",
       "      <td>1013945</td>\n",
       "      <td>1004771</td>\n",
       "      <td>11729</td>\n",
       "      <td>10.849342</td>\n",
       "      <td>24.377096</td>\n",
       "      <td>41.289827</td>\n",
       "      <td>41.605536</td>\n",
       "      <td>42.624785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>091620000000</th>\n",
       "      <td>1010220</td>\n",
       "      <td>1010221</td>\n",
       "      <td>1000792</td>\n",
       "      <td>61562</td>\n",
       "      <td>32652</td>\n",
       "      <td>0.369909</td>\n",
       "      <td>0.369909</td>\n",
       "      <td>0.376944</td>\n",
       "      <td>0.391089</td>\n",
       "      <td>0.418203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              probe-1  probe-2  probe-3  probe-4  probe-5  distance-1  distance-2  distance-3  distance-4  distance-5\n",
       "mun_key                                                                                                              \n",
       "081110000000    19869    22109    21574    19836    19837    0.219192    0.366082    0.396241    0.403501    0.403501\n",
       "082120000000    11194    52831    21421    21441      896    0.350609    0.350778    0.399705    0.422199    0.450911\n",
       "083110000000  1013945    11729  1004771  1010559    29215    0.660241    1.966321    3.476046    4.190831    6.377792\n",
       "084375001047    52839    19884    51094    52995    11296   11.799138   15.042199   24.252101   24.252101   26.778651\n",
       "081255007103    29222    18811    25329       81    29951   16.592880   16.720524   20.260771   20.842327   21.648458\n",
       "081275004047  1010576    62217    20250    55713    18811   17.252451   21.091341   26.484352   30.365620   31.501102\n",
       "081350020020     1506  1006858  1011407    53353    24357   22.270402   24.359167   24.929800   25.714412   28.041415\n",
       "083260003003    51017    32134  1009411    33886     6761   13.553900   14.697697   18.883913   26.284859   30.270263\n",
       "083370116116     4332  1005212  1013945  1004771    11729   10.849342   24.377096   41.289827   41.605536   42.624785\n",
       "091620000000  1010220  1010221  1000792    61562    32652    0.369909    0.369909    0.376944    0.391089    0.418203"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve lowest distances\n",
    "    # 5 lowest values for each mun_key (i.e., closest probes)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For each municipality (row in transposed view), find 5 closest probes\n",
    "closest_probes = {}\n",
    "\n",
    "for mun_key in df_probes_distance.columns:\n",
    "    # Get distances for this municipality across all probes\n",
    "    distances = df_probes_distance[mun_key]\n",
    "    \n",
    "    # Get the 5 smallest distances and their probe_ids\n",
    "    top5 = distances.nsmallest(5)\n",
    "    \n",
    "    closest_probes[mun_key] = {\n",
    "        f'probe-{i+1}': top5.index[i] for i in range(5)\n",
    "    } | {\n",
    "        f'distance-{i+1}': top5.values[i] for i in range(5)\n",
    "    }\n",
    "\n",
    "# Create df\n",
    "df_probes_sample = pd.DataFrame.from_dict(closest_probes, orient='index')\n",
    "df_probes_sample.index.name = 'mun_key'\n",
    "\n",
    "# Reorder columns to group probe IDs and distances together\n",
    "probe_cols = [f'probe-{i}' for i in range(1, 6)]\n",
    "dist_cols = [f'distance-{i}' for i in range(1, 6)]\n",
    "df_probes_sample = df_probes_sample[probe_cols + dist_cols]\n",
    "\n",
    "df_probes_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d995a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probes sampling saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write probe sampling to CSV\n",
    "df_probes_sample.to_csv('../data/processed/probes_sample.csv', encoding='utf-8')\n",
    "\n",
    "print(\"\\nProbes sampling saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc596a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mun_key  probe-1  probe-2  probe-3  probe-4  probe-5  distance-1  \\\n",
      "0  91620000000  1010220  1010221  1000792    61562    32652    0.369909   \n",
      "1  95640000000  1000661  1013659  1010379  1001538  1011139    0.286338   \n",
      "2  97610000000  1002071    31056    22386    34752  1014021    0.504603   \n",
      "3  94775437129      706    62428    50852    29659  1013075   14.131767   \n",
      "4  94755428146    50852      706  1013075  1011248    29659    6.241085   \n",
      "5  96775621181  1010374  1011093    52685    50445  1013840    6.035901   \n",
      "6  97740121121    10920    53353     1506    51834    50828   10.680619   \n",
      "7  92780118118  1007600  1008391  1003651  1007433  1007933   23.864524   \n",
      "8  95730120120    60757    15128    34005       46    22981    9.539632   \n",
      "\n",
      "   distance-2  distance-3  distance-4  distance-5 mun_name_short  \n",
      "0    0.369909    0.376944    0.391089    0.418203        München  \n",
      "1    0.390012    0.396487    0.396901    0.396901       Nürnberg  \n",
      "2    0.662187    0.758538    1.382201   10.924855       Augsburg  \n",
      "3   18.208114   21.986502   27.858359   30.682169     Kupferberg  \n",
      "4   16.068294   18.826251   27.432002   38.580194    Lichtenberg  \n",
      "5   10.633810   14.754627   27.263251   27.560321     Rothenfels  \n",
      "6   11.036602   26.905308   26.948735   30.272410         Burgau  \n",
      "7   24.133540   24.218074   24.351020   24.351020          Bogen  \n",
      "8   11.776192   11.783300   13.373189   16.543995     Langenzenn  \n"
     ]
    }
   ],
   "source": [
    "# Reduced Sampling for Bayern\n",
    "\n",
    "# Load ../data/processed/probes_sample.csv as df_probes_sample\n",
    "df_probes_sample = pd.read_csv('../data/processed/probes_sample.csv')\n",
    "\n",
    "# Load ../data/processed/municipalities_full_sample.csv as \n",
    "df_mun_sample = pd.read_csv('../data/processed/municipalities_full_sample.csv')\n",
    "\n",
    "# Select probes from df_probes_sample (whose mun_key belongs to state \"Bayern\" in df_mun_sample)\n",
    "df_mun_keys_bayern = df_mun_sample[df_mun_sample['state'] == 'Bayern']['mun_key']\n",
    "df_probes_bayern = df_probes_sample[df_probes_sample['mun_key'].isin(df_mun_keys_bayern)]\n",
    "\n",
    "# Add mun_name_short by merging with df_mun_sample\n",
    "df_probes_bayern = df_probes_bayern.merge(\n",
    "    df_mun_sample[['mun_key', 'mun_name_short']], \n",
    "    on='mun_key', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Print list of probes (9*5=45)\n",
    "\n",
    "# print(df_mun_keys_bayern.head(20))\n",
    "print(df_probes_bayern.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06bada61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique probes in the sample: 41\n",
      "Head: [46, 706, 1506, 10920, 15128]\n",
      "Tail: [1011248, 1013075, 1013659, 1013840, 1014021]\n",
      "\n",
      "Successfully written 41 unique probe IDs to text file.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Write probe sample to continuous list\n",
    "\n",
    "# Extract all probe IDs from the probe columns\n",
    "probe_ids = []\n",
    "for col in ['probe-1', 'probe-2', 'probe-3', 'probe-4', 'probe-5']:\n",
    "    # probe_ids.extend(df_probes_sample[col].tolist())  # large sample\n",
    "    probe_ids.extend(df_probes_bayern[col].tolist())  # small sample: Bayern\n",
    "\n",
    "# Get unique probe IDs\n",
    "unique_probe_ids = sorted(set(probe_ids))\n",
    "print(f\"\\nTotal unique probes in the sample: {len(unique_probe_ids)}\")\n",
    "print(\"Head:\", unique_probe_ids[:5])\n",
    "print(\"Tail:\", unique_probe_ids[-5:])\n",
    "\n",
    "# Write unique IDs to text file\n",
    "# with open('../data/processed/probes_sample_ids.txt', 'w') as f:  # large sample\n",
    "with open('../data/processed/probes_bayern_ids.txt', 'w') as f:  # small sample: Bayern\n",
    "    for probe_id in unique_probe_ids:\n",
    "        f.write(f\"{probe_id},\")  # seperated by comma\n",
    "\n",
    "print(f\"\\nSuccessfully written {len(unique_probe_ids)} unique probe IDs to text file.\")\n",
    "print(\"----\")\n",
    "\n",
    "# Check for multiple occurrences of each probe ID\n",
    "# probe_id_counts = pd.Series(all_probe_ids).value_counts().sort_values(ascending=False)\n",
    "# print(\"\\nCount probe IDs (number of times each probe appears in the sample):\\n\")\n",
    "# print(\"Head:\\n\", probe_id_counts.head(5))\n",
    "# print(\"\\nTail:\\n\", probe_id_counts.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94151a40",
   "metadata": {},
   "source": [
    "# Sampling Targets: Cloud Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69ddd4",
   "metadata": {},
   "source": [
    "### Set up Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling target machines for RIPE Atlas probes\n",
    "    # Dependencies:\n",
    "    # - ripe.atlas.cousteau\n",
    "    # - RIPE Atlas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement IDs: [155921813]\n"
     ]
    }
   ],
   "source": [
    "# Create a Measurement\n",
    "\n",
    "from ripe.atlas.cousteau import Ping, AtlasSource, AtlasCreateRequest\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "ATLAS_API_KEY = env_vars.get(\"atlas_key\")\n",
    "\n",
    "# Origin:\n",
    "probe_ids  = [1014162,1014259,1014434,1014441]\n",
    "\n",
    "# Target:\n",
    "hostnames = [\"aws-dub.ncc.dock.ee\"]  # more than one: will initiate multiple measurements\n",
    "\n",
    "# Schedule:\n",
    "CET = timezone(timedelta(hours=1))\n",
    "start = datetime(2026, 2, 18, 10, 15, tzinfo=CET)  # YYYY, MM, DD, HH, MM\n",
    "stop  = datetime(2026, 2, 18, 10, 45, tzinfo=CET)  # default: tzinfo=timezone.utc\n",
    "\n",
    "# Only one Ping definition per hostname\n",
    "measurements = [\n",
    "    Ping(\n",
    "        af=4, \n",
    "        target=hostname, \n",
    "        description=f\"Ping {hostname}\",  # af=6 for IPv6\n",
    "        #tags=[\"test\"],\n",
    "        packets=3,\n",
    "        size=48\n",
    "        packet_interval=100,    # ms between packets, default: 0\n",
    "        spread=30,              # spread probes over *observation interval* within *recurrence interval*\n",
    "        resolve_on_probe=true,  # local DNS lookup\n",
    "        skip_dns_check=false,   #\n",
    "        include_probe_id=true,  # include probe ID in results for matching\n",
    "        interval=300            # recurrence/frequency: e.g. every 5 min (omit if is_oneoff)\n",
    "    )\n",
    "    for hostname in hostnames\n",
    "]\n",
    "\n",
    "# One source with the explicit probe list\n",
    "source = AtlasSource(\n",
    "    type=\"probes\",\n",
    "    value=\",\".join(str(p) for p in probe_ids),\n",
    "    requested=len(probe_ids)\n",
    ")\n",
    "\n",
    "atlas_request = AtlasCreateRequest(\n",
    "    key=ATLAS_API_KEY,\n",
    "    measurements=measurements,\n",
    "    sources=[source],\n",
    "    is_oneoff=true,   # set True to ignore interval and run once\n",
    "    start_time=start,\n",
    "    stop_time=stop,\n",
    ")\n",
    "\n",
    "is_success, response = atlas_request.create()\n",
    "if is_success:\n",
    "    print(\"Measurement IDs:\", response.get(\"measurements\"))\n",
    "else:\n",
    "    print(\"Error:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91c87b",
   "metadata": {},
   "source": [
    "### Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c640ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: Target Machine Specifics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_machines = pd.read_excel(\n",
    "    '../data/processed/zones_v2.xlsx', \n",
    "    engine='calamine',\n",
    "    sheet_name='machines', \n",
    "    dtype={\n",
    "        'asn': str,\n",
    "        'ip4': str,\n",
    "        'ip6': str,\n",
    "        'hostname': str,\n",
    "        'machine_type': str,\n",
    "        'cost_h': 'float64',\n",
    "        'cost_runtime': 'float64',\n",
    "        'cpu': 'Int64',\n",
    "        'ram': 'Int64',\n",
    "        'netspeed': 'Int64'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nTarget machine data loaded successfully.\")\n",
    "# df_machines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16040082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: Zone Specifics\n",
    "\n",
    "# Import \"zones\" from ../data/processed/zones_v2.xlsx\n",
    "# to df_targets\n",
    "\n",
    "\n",
    "# base sheet: \"zones\"\n",
    "\n",
    "# add from \"machines\"\n",
    "    # asn\n",
    "    # ip4\n",
    "    # ip6\n",
    "    # host\n",
    "    # machine_type\n",
    "    # cost_h\n",
    "    # cost_runtime\n",
    "    # cpu\n",
    "    # ram\n",
    "    # netspeed\n",
    "\n",
    "# add from \"probes\"\n",
    "    # probe_id\n",
    "    \n",
    "    \n",
    "# Retrieve coordinates for lat, long, geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed43ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance matrix: coordinates in df_targets to coordinates in df_mun_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8c88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7e5638",
   "metadata": {},
   "source": [
    "### DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffff7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target machine data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data: Target Machine Specifics\n",
    "\n",
    "df_dns = pd.read_excel(\n",
    "    '../data/processed/zones_v2.xlsx', \n",
    "    engine='calamine',\n",
    "    sheet_name='dns', \n",
    "    dtype=str)  # Interpret all columns as string\n",
    "\n",
    "# Drop col \"asn\"\n",
    "df_dns = df_dns.drop(columns='asn')\n",
    "\n",
    "print(\"\\nMachine networking data loaded successfully.\")\n",
    "# df_dns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9d8300b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "\n",
    "df_dns_clean = df_dns.dropna(subset=['probe_id'])  # keep only rows with probe_id\n",
    "\n",
    "df_dns_clean = df_dns_clean[df_dns_clean['name'] != 'ovh-par']  # drop one entry due to incompatibility; manual setup\n",
    "\n",
    "# df_dns_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BIND DNS records file from df_dns to create domain names at Cloudflare\n",
    "\n",
    "# Dry-run\n",
    "# df_dns_clean = df_dns_clean.head(1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Insert df (if none present)\n",
    "\n",
    "# Define vars\n",
    "zone = \"dock.ee\"   # your zone/domain\n",
    "ttl  = 60          # TTL in seconds\n",
    "\n",
    "lines = [\n",
    "    f\"$ORIGIN {zone}.\",\n",
    "    f\"$TTL {ttl}\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "for _, row in df_dns_clean.iterrows():\n",
    "    hostname = row['hostname']\n",
    "    # Make hostname relative to zone, or use @ for apex\n",
    "    relative = hostname.replace(f\".{zone}\", \"\").replace(zone, \"@\")\n",
    "\n",
    "    if pd.notna(row.get('ip4')) and row['ip4']:\n",
    "        lines.append(f\"{relative}\\t{ttl}\\tIN\\tA\\t{row['ip4']}\")\n",
    "\n",
    "    if pd.notna(row.get('ip6')) and row['ip6']:\n",
    "        lines.append(f\"{relative}\\t{ttl}\\tIN\\tAAAA\\t{row['ip6']}\")\n",
    "\n",
    "zone_file = \"\\n\".join(lines)\n",
    "\n",
    "output_path = \"../data/processed/dns_cloudflare_bulk.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(zone_file)\n",
    "\n",
    "print(\"\\nDNS Zone file successfully written.\")\n",
    "# print(zone_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d942e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Hostnames to file (newlines)\n",
    "\n",
    "df_dns_lists = df_dns.dropna(subset=['probe_id'])  # keep only rows with probe_id\n",
    "\n",
    "# Export hostnames and IPs to text file\n",
    "with open('../data/processed/hostnames.txt', 'w') as f:\n",
    "    for _, row in df_dns_lists.iterrows():\n",
    "        f.write(f\"{row['hostname']},{row['ip4']},{row['ip6']}\\n\")  # newline for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "78c5b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Hostnames to file (single line)\n",
    "\n",
    "df_dns_lists = df_dns.dropna(subset=['probe_id'])  # keep only rows with probe_id\n",
    "\n",
    "# Export hostnames and IPs to text file\n",
    "with open('../data/processed/hostnames.txt', 'w') as f:\n",
    "    values = []\n",
    "    for _, row in df_dns_lists.iterrows():\n",
    "        values.extend([str(row['hostname']), str(row['ip4']), str(row['ip6'])])  # all on a single line\n",
    "    f.write(','.join(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a160260d",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example RIPE Atlas API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "probe_id = 1014464\n",
    "response = requests.get(f\"https://atlas.ripe.net/api/v2/probes/{probe_id}/\")\n",
    "data = response.json()\n",
    "\n",
    "json_data = response.json()  # Parse JSON\n",
    "print(json.dumps(json_data, indent=4)) # Print with indentation\n",
    "\n",
    "coordinates = data['geometry']['coordinates']\n",
    "longitude, latitude = coordinates\n",
    "\n",
    "# Display as individual values\n",
    "latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example geopy using OSM\n",
    "\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "location = geolocator.geocode(\"Frankfurt am Main, 60311\")\n",
    "\n",
    "if location:\n",
    "    print(f\"Location: {location.address}\")\n",
    "    print(f\"Latitude: {location.latitude}\")\n",
    "    print(f\"Longitude: {location.longitude}\")\n",
    "else:\n",
    "    print(\"Location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f605e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage OpenPLZ API\n",
    "# Dependencies: -\n",
    "\n",
    "# Shell: curl -X GET 'https://openplzapi.org/de/FederalStates' -H 'accept: text/json' | ConvertFrom-Json | ConvertTo-Json\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# GET request to API\n",
    "# List all federal states in Germany\n",
    "response = requests.get('https://openplzapi.org/de/FederalStates')\n",
    "\n",
    "# print(response.text)  # Print raw response\n",
    "# print(response.json())  # Print raw JSON object\n",
    "# response.json() # Print in native-style\n",
    "\n",
    "json_data = response.json()  # Parse JSON\n",
    "print(json.dumps(json_data, indent=4)) # Print with indentation\n",
    "\n",
    "# Write JSON\n",
    "# with open('output.json', 'w') as f:\n",
    "#     json.dump(json_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
